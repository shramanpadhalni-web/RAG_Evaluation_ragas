{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory (where your notebook is)\n",
    "current_dir = Path().resolve()\n",
    "\n",
    "# Go two levels up to reach the base directory ('some/')\n",
    "base_dir = current_dir.parent\n",
    "\n",
    "# Add the base directory to the system path\n",
    "sys.path.append(str(base_dir))\n",
    "\n",
    "from db_retriever_module import ChromadbRetrieverModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerGenerator(dspy.Signature):\n",
    "    \"\"\"\n",
    "    A class to generate answers to questions based on provided context using DSPy's Signature.\n",
    "    \n",
    "    Attributes:\n",
    "        context (dspy.InputField): Text that may contain relevant facts for generating an answer.\n",
    "        question (dspy.InputField): The question for which an answer is sought.\n",
    "        answer (dspy.OutputField): The generated short factual answer, aimed to be between 1 to 15 words.\n",
    "    \"\"\"\n",
    "    context = dspy.InputField(description=\"May contain relevant facts for answering.\")\n",
    "    question = dspy.InputField(description=\"The question to be answered.\")\n",
    "    answer = dspy.OutputField(description=\"Short factual answer to the question, typically 1-15 words.\")\n",
    "\n",
    "class RetrievalAugmentedGenerator(dspy.Module):\n",
    "    \"\"\"\n",
    "    Implements a Retrieval-Augmented Generation (RAG) model by combining retrieval and generation capabilities.\n",
    "\n",
    "    This model first retrieves relevant passages based on the input question and then generates an answer\n",
    "    by considering both the question and the retrieved context.\n",
    "    \n",
    "    Attributes:\n",
    "        num_passages (int): Number of passages to retrieve for context enrichment.\n",
    "        retrieve (dspy.Retrieve): The retrieval component of the RAG model.\n",
    "        generate_answer (dspy.ChainOfThought): The answer generation component based on retrieved context.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_passages=5):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(AnswerGenerator)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        \"\"\"\n",
    "        Retrieves relevant passages based on the question and generates an answer.\n",
    "\n",
    "        Args:\n",
    "            question (str): The input question for which an answer is needed.\n",
    "        \n",
    "        Returns:\n",
    "            dspy.Prediction: The context used for answering and the generated answer.\n",
    "        \"\"\"\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import dspy\n",
    "\n",
    "# Assuming RAG and ChromadbRM classes are defined elsewhere in your code\n",
    "# from your_module import RAG, ChromadbRM\n",
    "\n",
    "def setup():\n",
    "    \"\"\"\n",
    "    Initializes and configures the DSPy library for a Retrieval-Augmented Generation (RAG) setup.\n",
    "    \n",
    "    This involves configuring a language model and a retrieval model with specified settings,\n",
    "    and then initializing the RAG module with these configurations.\n",
    "\n",
    "    Returns:\n",
    "        An instance of the RAG class, ready for use.\n",
    "        \n",
    "    Raises:\n",
    "        EnvironmentError: If the OPENAI_API_KEY environment variable is not set.\n",
    "        Exception: For general exceptions related to DSPy configuration or RAG initialization.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Retrieve the OpenAI API key safely\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            raise EnvironmentError(\"OPENAI_API_KEY not set in environment variables.\")\n",
    "        \n",
    "        # Configuration parameters\n",
    "        MODEL_NAME = 'gpt-3.5-turbo'\n",
    "        COLLECTION_NAME = \"test-overlap-0\"\n",
    "        PERSIST_DIR = \"local_chroma.db\"\n",
    "        LOCAL_EMBED_MODEL = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "        \n",
    "        # Configuring the language model\n",
    "        turbo = dspy.OpenAI(model=MODEL_NAME)\n",
    "        \n",
    "        # Configuring the retrieval model\n",
    "        chroma_rm = ChromadbRetrieverModule(db_collection_name=COLLECTION_NAME, persist_directory=PERSIST_DIR,\n",
    "                               local_embed_model=LOCAL_EMBED_MODEL, api_key=openai_api_key)\n",
    "        \n",
    "        # Apply the configurations\n",
    "        dspy.settings.configure(lm=turbo, rm=chroma_rm)\n",
    "        \n",
    "        # Initialize the RAG module\n",
    "        rag_instance = RetrievalAugmentedGenerator()\n",
    "        \n",
    "        logging.info(\"RAG setup completed successfully.\")\n",
    "        \n",
    "        return rag_instance\n",
    "        \n",
    "    except EnvironmentError as env_err:\n",
    "        logging.error(f\"Environment error during setup: {env_err}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to complete RAG setup: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You saved it in the validate synthetics data ipynb  - synthetic_dataset.csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), 'medical_tc_test.csv')\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(),\"processed\",\"synthetic_dataset.csv\"))\n",
    "\n",
    "df = df[['question', 'ground_truths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
